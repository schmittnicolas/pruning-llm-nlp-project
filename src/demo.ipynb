{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/nlpa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model_config import ModelConfig\n",
    "from pruning_methods.wanda import wanda_pruning\n",
    "from pruning_methods.magnitude import magnitude_pruning\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'facebook/opt-350m' from cache directory '.my_cache/llm_weights/'...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from evaluation_pruning import generate_text\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "llama_model = \"meta-llama/Llama-3.2-1B\"\n",
    "modelConfig = ModelConfig(token=token)\n",
    "model = modelConfig.load_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count the total number of non-zero parameters in a model.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to count parameters for\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (total non-zero parameters, trainable non-zero parameters)\n",
    "    \"\"\"\n",
    "    total_nonzero_params = 0\n",
    "    trainable_nonzero_params = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        num_nonzero_params = torch.count_nonzero(param).item()  # Count non-zero elements\n",
    "        total_nonzero_params += num_nonzero_params\n",
    "        if param.requires_grad:\n",
    "            trainable_nonzero_params += num_nonzero_params\n",
    "    \n",
    "    return total_nonzero_params, trainable_nonzero_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in original model: (331195120, 331195120)\n",
      "number of parameters in prunned model: (166761506, 166761506)\n"
     ]
    }
   ],
   "source": [
    "prunedModelConfig = modelConfig.copy_model()\n",
    "\n",
    "original_model = modelConfig.model\n",
    "prunned_model = prunedModelConfig.model\n",
    "\n",
    "pruning_result = magnitude_pruning(prunned_model, 0.5)\n",
    "\n",
    "print(f\"number of parameters in original model: {count_parameters(original_model)}\")\n",
    "print(f\"number of parameters in prunned model: {count_parameters(prunned_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikitext Perplexity:   4%|â–Ž         | 5/140 [00:23<10:24,  4.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m prunned_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mglobal_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprunedModelConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:201\u001b[0m, in \u001b[0;36mglobal_evaluation\u001b[0;34m(modelConfig, device)\u001b[0m\n\u001b[1;32m    198\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generate_text(modelConfig\u001b[38;5;241m.\u001b[39mmodel, modelConfig\u001b[38;5;241m.\u001b[39mtokenizer, PROMPT)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Perplexity evaluation\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m ppl_test \u001b[38;5;241m=\u001b[39m \u001b[43meval_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Inference time evaluation\u001b[39;00m\n\u001b[1;32m    204\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m measure_inference_time(modelConfig\u001b[38;5;241m.\u001b[39mmodel, modelConfig\u001b[38;5;241m.\u001b[39mnsamples, \n\u001b[1;32m    205\u001b[0m                                      modelConfig\u001b[38;5;241m.\u001b[39mseed, modelConfig\u001b[38;5;241m.\u001b[39mseqlen, modelConfig\u001b[38;5;241m.\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:71\u001b[0m, in \u001b[0;36meval_perplexity\u001b[0;34m(args, model, tokenizer, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Evaluate ppl in no grad context to avoid updating the model\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 71\u001b[0m     ppl_test \u001b[38;5;241m=\u001b[39m \u001b[43meval_ppl_wikitext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ppl_test\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:34\u001b[0m, in \u001b[0;36meval_ppl_wikitext\u001b[0;34m(model, testenc, bs, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m bs, nsamples)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Prepare inputs and move to device\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtestenc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseqlen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseqlen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mreshape(j \u001b[38;5;241m-\u001b[39m i, model\u001b[38;5;241m.\u001b[39mseqlen)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluation_pruning import global_evaluation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prunned_model.to(device)\n",
    "\n",
    "global_evaluation(prunedModelConfig, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.01\n",
      "(327906570, 327906570)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.11\n",
      "(295016699, 295016699)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.21\n",
      "(262126971, 262126971)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.31\n",
      "(229230228, 229230228)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.41\n",
      "(196347344, 196347344)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.51\n",
      "(163468216, 163468216)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.61\n",
      "(130586282, 130586282)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.71\n",
      "(97696610, 97696610)\n",
      "(331195120, 331195120)\n",
      "Pruning ratio: 0.81\n",
      "(64834045, 64834045)\n",
      "(331195120, 331195120)\n"
     ]
    }
   ],
   "source": [
    "from evaluation_pruning import global_evaluation\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "original_model.to(device)\n",
    "prunned_model.to(device)\n",
    "\n",
    "results = []\n",
    "ratios = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "for ratio in ratios:\n",
    "    ratio = ratio / 100\n",
    "    print(f\"Pruning ratio: {ratio}\")\n",
    "    tmpModelConfig = modelConfig.copy_model()\n",
    "    pruning_result = magnitude_pruning(tmpModelConfig.model, ratio)\n",
    "    results.append(global_evaluation(tmpModelConfig, device=device))\n",
    "\n",
    "    print(count_parameters(tmpModelConfig.model))\n",
    "    print(count_parameters(modelConfig.model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[662538026, 662538026, 662538026, 662538026, 662538026, 662538026, 662538026, 662538026, 662538026]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f75b04eb9d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot memory size over pruning ratio\n",
    "model_size_bytes = [result[\"memory\"][\"model_size_bytes\"] for result in results]\n",
    "print(model_size_bytes)\n",
    "plt.plot(ratios, [result[\"memory\"][\"model_size_bytes\"] for result in results])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanda_pruning(modelConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
