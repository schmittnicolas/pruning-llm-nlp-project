{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/nlpa/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model_config import ModelConfig\n",
    "from pruning_methods.wanda import wanda_pruning\n",
    "from pruning_methods.magnitude import magnitude_pruning\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 'facebook/opt-350m' from cache directory '.cache/llm_weights/'...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from evaluation_pruning import generate_text\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "llama_model = \"meta-llama/Llama-3.2-1B\"\n",
    "modelConfig = ModelConfig(token=token)\n",
    "model = modelConfig.load_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count the total number of non-zero parameters in a model.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to count parameters for\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (total non-zero parameters, trainable non-zero parameters)\n",
    "    \"\"\"\n",
    "    total_nonzero_params = 0\n",
    "    trainable_nonzero_params = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        num_nonzero_params = torch.count_nonzero(param).item()  # Count non-zero elements\n",
    "        total_nonzero_params += num_nonzero_params\n",
    "        if param.requires_grad:\n",
    "            trainable_nonzero_params += num_nonzero_params\n",
    "    \n",
    "    return total_nonzero_params, trainable_nonzero_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in original model: (331195120, 331195120)\n",
      "number of parameters in prunned model: (166761506, 166761506)\n"
     ]
    }
   ],
   "source": [
    "prunedModelConfig = modelConfig.copy_model()\n",
    "\n",
    "original_model = modelConfig.model\n",
    "prunned_model = prunedModelConfig.model\n",
    "\n",
    "pruning_result = magnitude_pruning(prunned_model, 0.5)\n",
    "\n",
    "print(f\"number of parameters in original model: {count_parameters(original_model)}\")\n",
    "print(f\"number of parameters in prunned model: {count_parameters(prunned_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m prunned_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mglobal_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprunedModelConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:165\u001b[0m, in \u001b[0;36mglobal_evaluation\u001b[0;34m(modelConfig, device)\u001b[0m\n\u001b[1;32m    162\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generate_text(modelConfig\u001b[38;5;241m.\u001b[39mmodel, modelConfig\u001b[38;5;241m.\u001b[39mtokenizer, PROMPT)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Perplexity evaluation\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m ppl_test \u001b[38;5;241m=\u001b[39m \u001b[43meval_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Compile all metrics\u001b[39;00m\n\u001b[1;32m    168\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_size_bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m: memory_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     }\n\u001b[1;32m    182\u001b[0m }\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:69\u001b[0m, in \u001b[0;36meval_perplexity\u001b[0;34m(args, model, tokenizer, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_perplexity\u001b[39m(args, model, tokenizer, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Get the test loader\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     _, testloader \u001b[38;5;241m=\u001b[39m \u001b[43mget_wikitext2\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseqlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Evaluate ppl in no grad context to avoid updating the model\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/data_loading.py:45\u001b[0m, in \u001b[0;36mget_wikitext2\u001b[0;34m(nsamples, seed, seqlen, tokenizer)\u001b[0m\n\u001b[1;32m     42\u001b[0m testdata \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitext-2-raw-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Encode datasets\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m trainenc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraindata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m testenc \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(testdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Generate samples from training set\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2859\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2860\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2970\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2949\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2950\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2968\u001b[0m     )\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3046\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3037\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3038\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3039\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3043\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3044\u001b[0m )\n\u001b[0;32m-> 3046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_special_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3066\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3067\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:137\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m )\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:600\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    578\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    598\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    599\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 600\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:127\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m )\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:526\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 526\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    538\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    540\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    550\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluation_pruning import global_evaluation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prunned_model.to(device)\n",
    "\n",
    "global_evaluation(prunedModelConfig, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikitext Perplexity: 100%|██████████| 20/20 [01:26<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikitext Perplexity: 100%|██████████| 20/20 [01:26<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikitext Perplexity: 100%|██████████| 20/20 [01:26<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikitext Perplexity: 100%|██████████| 20/20 [01:26<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikitext Perplexity: 100%|██████████| 20/20 [01:26<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning ratio: 0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m tmpModelConfig \u001b[38;5;241m=\u001b[39m modelConfig\u001b[38;5;241m.\u001b[39mcopy_model()\n\u001b[1;32m     13\u001b[0m pruning_result \u001b[38;5;241m=\u001b[39m magnitude_pruning(prunned_model, ratio)\n\u001b[0;32m---> 14\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mglobal_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpModelConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:165\u001b[0m, in \u001b[0;36mglobal_evaluation\u001b[0;34m(modelConfig, device)\u001b[0m\n\u001b[1;32m    162\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m generate_text(modelConfig\u001b[38;5;241m.\u001b[39mmodel, modelConfig\u001b[38;5;241m.\u001b[39mtokenizer, PROMPT)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Perplexity evaluation\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m ppl_test \u001b[38;5;241m=\u001b[39m \u001b[43meval_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Compile all metrics\u001b[39;00m\n\u001b[1;32m    168\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_size_bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m: memory_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     }\n\u001b[1;32m    182\u001b[0m }\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/evaluation_pruning.py:69\u001b[0m, in \u001b[0;36meval_perplexity\u001b[0;34m(args, model, tokenizer, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_perplexity\u001b[39m(args, model, tokenizer, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Get the test loader\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     _, testloader \u001b[38;5;241m=\u001b[39m \u001b[43mget_wikitext2\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseqlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Evaluate ppl in no grad context to avoid updating the model\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Prog/pruning-llm-nlp-project/src/data_loading.py:45\u001b[0m, in \u001b[0;36mget_wikitext2\u001b[0;34m(nsamples, seed, seqlen, tokenizer)\u001b[0m\n\u001b[1;32m     42\u001b[0m testdata \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikitext-2-raw-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Encode datasets\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m trainenc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraindata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m testenc \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(testdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Generate samples from training set\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2859\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2860\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2970\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2949\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2950\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2968\u001b[0m     )\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3046\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3037\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3038\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3039\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3043\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3044\u001b[0m )\n\u001b[0;32m-> 3046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_special_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3066\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3067\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:137\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m )\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:600\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    578\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    598\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    599\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 600\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:127\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m )\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlpa/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:526\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 526\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    538\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    540\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    550\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluation_pruning import global_evaluation\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "original_model.to(device)\n",
    "prunned_model.to(device)\n",
    "\n",
    "results = []\n",
    "ratios = range(1, 90, 10)\n",
    "for ratio in ratios:\n",
    "    ratio = ratio / 100\n",
    "    print(f\"Pruning ratio: {ratio}\")\n",
    "    tmpModelConfig = modelConfig.copy_model()\n",
    "    pruning_result = magnitude_pruning(prunned_model, ratio)\n",
    "    results.append(global_evaluation(tmpModelConfig, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.599618911743164, 23.599618911743164, 23.599618911743164, 23.599618911743164, 23.599618911743164]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5bb81a0e90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexities = [result[\"perplexity\"][\"test_ppl\"] for result in results]\n",
    "print(perplexities)\n",
    "plt.plot(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[662538026, 662538026, 662538026, 662538026, 662538026, 662538026, 662538026, 662538026, 662538026]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f811dfdc850>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot memory size over pruning ratio\n",
    "model_size_bytes = [result[\"memory\"][\"model_size_bytes\"] for result in results]\n",
    "print(model_size_bytes)\n",
    "plt.plot(ratios, [result[\"memory\"][\"model_size_bytes\"] for result in results])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wanda Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanda_pruning(modelConfig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
